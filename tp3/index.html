
<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Les Travaux Pratiques du cours Big Data">
      
      
        <link rel="canonical" href="http://INSATunisia.github.io/TP-BigData/tp3/">
      
      
        <meta name="author" content="Lilia Sfaxi">
      
      
        <link rel="shortcut icon" href="../img/favicon.ico">
      
      <meta name="generator" content="mkdocs-0.17.2, mkdocs-material-1.7.1">
    
    
      
        <title>TP3 - Apacke Kafka - TP Big Data</title>
      
    
    
      <script src="../assets/javascripts/modernizr-1df76c4e58.js"></script>
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application-2421e7e627.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-8817cfa535.palette.css">
      
    
    
      
        
        
        
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    

    <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
    <link rel="stylesheet" href="../css/highlight.css">
    <link rel="stylesheet" href="../css/codehilite.css">
    <link rel="stylesheet" href="../css/tooltip.css">

    <link rel="stylesheet" href="../css/customizations.css">
    <link rel="stylesheet" href="../css/site-customizations.css">
  </head>
  
  
  
  
    <body data-md-color-primary="blue" data-md-color-accent="yellow">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <a href="http://INSATunisia.github.io/TP-BigData/" title="TP Big Data" class="md-logo md-header-nav__button">
            <img src="../img/logo.png" width="24" height="24">
          </a>
        
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <span class="md-flex__ellipsis md-header-nav__title">
          
            
              
            
            TP3 - Apacke Kafka
          
        </span>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
          
<div class="md-search" data-md-component="search">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" accesskey="s" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">close</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result" data-md-lang-search="">
          <div class="md-search-result__meta" data-md-lang-result-none="No matching documents" data-md-lang-result-one="1 matching document" data-md-lang-result-other="# matching documents">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <div class="md-header-nav__source">
          
            


  


  <a href="https://github.com/INSATunisia/TP-BigData/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      INSATunisia/TP-BigData
    </div>
  </a>

          
        </div>
      </div>
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    
      <i class="md-logo md-nav__button">
        <img src="../img/logo.png">
      </i>
    
    TP Big Data
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/INSATunisia/TP-BigData/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      INSATunisia/TP-BigData
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Travaux Pratiques Big Data" class="md-nav__link">
      Travaux Pratiques Big Data
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../tp1/" title="TP1 - Hadoop et Map Reduce" class="md-nav__link">
      TP1 - Hadoop et Map Reduce
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../tp2/" title="TP2 - Apache Spark" class="md-nav__link">
      TP2 - Apache Spark
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        TP3 - Apacke Kafka
      </label>
    
    <a href="./" title="TP3 - Apacke Kafka" class="md-nav__link md-nav__link--active">
      TP3 - Apacke Kafka
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#telecharger-pdf" title="Télécharger PDF" class="md-nav__link">
    Télécharger PDF
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#objectifs-du-tp" title="Objectifs du TP" class="md-nav__link">
    Objectifs du TP
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#outils-et-versions" title="Outils et Versions" class="md-nav__link">
    Outils et Versions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kafka" title="Kafka" class="md-nav__link">
    Kafka
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quest-ce-quun-systeme-de-messaging" title="Qu'est-ce qu'un système de messaging?" class="md-nav__link">
    Qu'est-ce qu'un système de messaging?
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-systemes-de-messaging-point-a-point" title="1. Systèmes de messaging Point à Point" class="md-nav__link">
    1. Systèmes de messaging Point à Point
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-systemes-de-messaging-publishsubscribe" title="2. Systèmes de messaging Publish/Subscribe" class="md-nav__link">
    2. Systèmes de messaging Publish/Subscribe
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#presentation-de-kafka" title="Présentation de Kafka" class="md-nav__link">
    Présentation de Kafka
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture-de-kafka" title="Architecture de Kafka" class="md-nav__link">
    Architecture de Kafka
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kafka-et-zookeeper" title="Kafka et Zookeeper" class="md-nav__link">
    Kafka et Zookeeper
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#installation" title="Installation" class="md-nav__link">
    Installation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#premiere-utilisation-de-kafka" title="Première utilisation de Kafka" class="md-nav__link">
    Première utilisation de Kafka
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creation-dun-topic" title="Création d'un topic" class="md-nav__link">
    Création d'un topic
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exemple-producteur-consommateur" title="Exemple Producteur Consommateur" class="md-nav__link">
    Exemple Producteur Consommateur
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configuration-de-plusieurs-brokers" title="Configuration de plusieurs brokers" class="md-nav__link">
    Configuration de plusieurs brokers
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#creation-dune-application-personnalisee" title="Création d'une application personnalisée" class="md-nav__link">
    Création d'une application personnalisée
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#producteur" title="Producteur" class="md-nav__link">
    Producteur
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consommateur" title="Consommateur" class="md-nav__link">
    Consommateur
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integration-de-kafka-avec-spark" title="Intégration de Kafka avec Spark" class="md-nav__link">
    Intégration de Kafka avec Spark
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#utilite" title="Utilité" class="md-nav__link">
    Utilité
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#realisation" title="Réalisation" class="md-nav__link">
    Réalisation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#homework" title="Homework" class="md-nav__link">
    Homework
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../tp4/" title="TP4 - HBase" class="md-nav__link">
      TP4 - HBase
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#telecharger-pdf" title="Télécharger PDF" class="md-nav__link">
    Télécharger PDF
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#objectifs-du-tp" title="Objectifs du TP" class="md-nav__link">
    Objectifs du TP
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#outils-et-versions" title="Outils et Versions" class="md-nav__link">
    Outils et Versions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kafka" title="Kafka" class="md-nav__link">
    Kafka
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quest-ce-quun-systeme-de-messaging" title="Qu'est-ce qu'un système de messaging?" class="md-nav__link">
    Qu'est-ce qu'un système de messaging?
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-systemes-de-messaging-point-a-point" title="1. Systèmes de messaging Point à Point" class="md-nav__link">
    1. Systèmes de messaging Point à Point
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-systemes-de-messaging-publishsubscribe" title="2. Systèmes de messaging Publish/Subscribe" class="md-nav__link">
    2. Systèmes de messaging Publish/Subscribe
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#presentation-de-kafka" title="Présentation de Kafka" class="md-nav__link">
    Présentation de Kafka
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture-de-kafka" title="Architecture de Kafka" class="md-nav__link">
    Architecture de Kafka
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kafka-et-zookeeper" title="Kafka et Zookeeper" class="md-nav__link">
    Kafka et Zookeeper
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#installation" title="Installation" class="md-nav__link">
    Installation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#premiere-utilisation-de-kafka" title="Première utilisation de Kafka" class="md-nav__link">
    Première utilisation de Kafka
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creation-dun-topic" title="Création d'un topic" class="md-nav__link">
    Création d'un topic
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exemple-producteur-consommateur" title="Exemple Producteur Consommateur" class="md-nav__link">
    Exemple Producteur Consommateur
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configuration-de-plusieurs-brokers" title="Configuration de plusieurs brokers" class="md-nav__link">
    Configuration de plusieurs brokers
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#creation-dune-application-personnalisee" title="Création d'une application personnalisée" class="md-nav__link">
    Création d'une application personnalisée
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#producteur" title="Producteur" class="md-nav__link">
    Producteur
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consommateur" title="Consommateur" class="md-nav__link">
    Consommateur
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integration-de-kafka-avec-spark" title="Intégration de Kafka avec Spark" class="md-nav__link">
    Intégration de Kafka avec Spark
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#utilite" title="Utilité" class="md-nav__link">
    Utilité
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#realisation" title="Réalisation" class="md-nav__link">
    Réalisation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#homework" title="Homework" class="md-nav__link">
    Homework
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/INSATunisia/TP-BigData/edit/master/docs/tp3.md" title="Edit this page" class="md-icon md-content__icon">edit</a>
                
                
                <h1 id="tp3-la-collecte-de-donnees-avec-le-bus-kafka">TP3 - La Collecte de Données avec le Bus Kafka<a class="headerlink" href="#tp3-la-collecte-de-donnees-avec-le-bus-kafka" title="Permanent link">&para;</a></h1>
<p><center><img alt="Distributed Data Collection" src="../img/collect.png" /></center></p>
<h2 id="telecharger-pdf">Télécharger PDF<a class="headerlink" href="#telecharger-pdf" title="Permanent link">&para;</a></h2>
<p><a href="../tp3.pdf"><img alt="Download TP3" src="../img/pdf.png" /></a></p>
<h2 id="objectifs-du-tp">Objectifs du TP<a class="headerlink" href="#objectifs-du-tp" title="Permanent link">&para;</a></h2>
<p>Utilisation de Kafka pour une collecte de données distribuée, et intégration avec Spark.</p>
<h2 id="outils-et-versions">Outils et Versions<a class="headerlink" href="#outils-et-versions" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="https://kafka.apache.org/">Apache Kafka</a> Version 2.11-0.8.2.1</li>
<li><a href="http://hadoop.apache.org/">Apache Hadoop</a> Version: 2.7.2</li>
<li><a href="https://spark.apache.org/">Apache Spark</a> Version: 2.2.1</li>
<li><a href="https://www.docker.com/">Docker</a> Version 17.09.1</li>
<li><a href="https://www.jetbrains.com/idea/download/">IntelliJ IDEA</a> Version Ultimate 2016.1 (ou tout autre IDE de votre choix)</li>
<li><a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">Java</a> Version 1.8</li>
<li>Unix-like ou Unix-based Systems (Divers Linux et MacOS)</li>
</ul>
<h2 id="kafka">Kafka<a class="headerlink" href="#kafka" title="Permanent link">&para;</a></h2>
<h3 id="quest-ce-quun-systeme-de-messaging">Qu'est-ce qu'un système de messaging?<a class="headerlink" href="#quest-ce-quun-systeme-de-messaging" title="Permanent link">&para;</a></h3>
<p>Un système de messaging (<em>Messaging System</em>) est responsable du transfert de données d'une application à une autre, de manière à ce que les applications puissent se concentrer sur les données sans s'inquiéter de la manière de les partager ou de les collecter. Le messaging distribué est basé sur le principe de file de message fiable. Les messages sont stockés de manière asynchrone dans des files d'attente entre les applications clientes et le système de messaging.</p>
<p>Deux types de patrons de messaging existent: Les systèmes "<em>point à point</em>" et les systèmes "<em>publish-subscribe</em>".</p>
<h4 id="1-systemes-de-messaging-point-a-point">1. Systèmes de messaging Point à Point<a class="headerlink" href="#1-systemes-de-messaging-point-a-point" title="Permanent link">&para;</a></h4>
<p>Dans un système point à point, les messages sont stockés dans une file. un ou plusieurs consommateurs peuvent consommer les message dans la file, mais un message ne peut être consommé que par un seul consommateur à la fois. Une fois le consommateur lit le message, ce dernier disparaît de la file.</p>
<p><center><br />
<img alt="Messaging Point à Point" src="../img/tp3/point-to-point.gif" /><br />
</center></p>
<h4 id="2-systemes-de-messaging-publishsubscribe">2. Systèmes de messaging Publish/Subscribe<a class="headerlink" href="#2-systemes-de-messaging-publishsubscribe" title="Permanent link">&para;</a></h4>
<p>Dans un système publish-subscribe, les messages sont stockés dans un "<em>topic</em>". Contrairement à un système point à point, les consommateurs peuvent souscrire à un ou plusieurs topics et consommer tous les messages de ce topic.</p>
<p><center><br />
<img alt="Messaging Point à Point" src="../img/tp3/pub-sub.gif" /><br />
</center></p>
<h3 id="presentation-de-kafka">Présentation de Kafka<a class="headerlink" href="#presentation-de-kafka" title="Permanent link">&para;</a></h3>
<p>Apache <a href="https://kafka.apache.org/">Kafka</a> est une plateforme de streaming qui bénéficie de trois fonctionnalités:</p>
<ol>
<li>Elle vous permet de publier et souscrire à un flux d'enregistrements. Elle ressemble ainsi à une file demessage ou un système de messaging d'entreprise.</li>
<li>Elle permet de stocker des flux d'enregistrements d'une façon tolérante aux pannes.</li>
<li>Elle vous permet de traiter (au besoin) les enregistrements au fur et à mesure qu'ils arrivent.</li>
</ol>
<p><center><img src="../img/kafka.png" width="200"></center></p>
<p>Les principaux avantages de Kafka sont:</p>
<ol>
<li><strong><em>La fiablitié</em></strong>: Kafka est distribué, partitionné, répliqué et tolérent aux fautes.</li>
<li><strong><em>La scalabilité</em></strong>: Kafka se met à l'échelle facilement et sans temps d'arrêt.</li>
<li><strong><em>La durabilité</em></strong>: Kafka utilise un <em>commit log</em> distribué, ce qui permet de stocker les messages sur le disque le plus vite possible.</li>
<li><strong><em>La performance</em></strong>: Kafka a un débit élevé pour la publication et l'abonnement.</li>
</ol>
<h3 id="architecture-de-kafka">Architecture de Kafka<a class="headerlink" href="#architecture-de-kafka" title="Permanent link">&para;</a></h3>
<p>Pour comprendre le fonctionnement de Kafka, il faut d'abord se familiariser avec le vocabulaire suivant:</p>
<ol>
<li><strong>Topic</strong>: Un flux de messages appartenant à une catégorie particulière. Les données sont stockées dans des topics.</li>
<li><strong>Partitions</strong>: Chaque topic est divisé en partitions. Pour chaque topic, Kafka conserve un minimum d'une partition. Chaque partition contient des messages dans une séquence ordonnée immuable. Une partition est implémentée comme un ensemble de sègments de tailles égales.</li>
<li><strong>Offset</strong>: Les enregistrements d'une partition ont chacun un identifiant séquentiel appelé <em>offset</em>, qui permet de l'identifier de manière unique dans la partition.</li>
<li><strong>Répliques</strong>: Les répliques sont des <em>backups</em> d'une partition. Elles ne sont jamais lues ni modifiées par les acteurs externes, elles servent uniquement à prévenir la perte de données.</li>
<li><strong>Brokers</strong>: Les <em>brokers</em> (ou courtiers) sont de simples systèmes responsables de maintenir les données publiées. Chaque courtier peut avoir zéro ou plusieurs partitions par topic. Si un topic admet N partitions et N courtiers, chaque courtier va avoir une seule partition. Si le nombre de courtiers est plus grand que celui des partitions, certains n'auront aucune partition de ce topic.</li>
<li><strong>Cluster</strong>: Un système Kafka ayant plus qu'un seul Broker est appelé <em>cluster Kafka</em>. L'ajout de nouveau brokers est fait de manière transparente sans temps d'arrêt.</li>
<li><strong>Producers</strong>: Les producteurs sont les éditeurs de messages à un ou plusieurs topics Kafka. Ils envoient des données aux courtiers Kafka. Chaque fois qu'un producteur publie un message à un courtier, ce dernier rattache le message au dernier sègment, ajouté ainsi à une partition. Un producteur peut également envoyer un message à une partition particulière.</li>
<li><strong>Consumers</strong>: Les consommateurs lisent les données à partir des brokers. Ils souscrivent à un ou plusieurs topics, et consomment les messages publiés en extrayant les données à partir des brokers.</li>
<li><strong>Leaders</strong>: Le leader est le noeud responsable de toutes les lectures et écritures d'une partition donnée. Chaque partition a un serveur jouant le rôle de leader.</li>
<li><strong>Follower</strong>: C'est un noeud qui suit les instructions du leader. Si le leader tombe en panne, l'un des followers deviendra automatiquement le nouveau leader.</li>
</ol>
<p>La figure suivante montre un exemple de flux entre les différentes parties d'un système Kafka:<br />
<center><br />
<img alt="Architecture Kafka" src="../img/tp3/archi.jpg" /><br />
</center></p>
<p>Dans cet exemple, un topic est configuré en trois partitions.</p>
<p>En supposant que, si le facteur de réplication du topic est de 3, alors Kafka va créer trois répliques identiques de chaque partition et les placer dans le cluster pour les rendre disponibles pour toutes les opérations. L'identifiant de la réplique est le même que l'identifiant du serveur qui l'héberge. Pour équilibrer la charge dans le cluster, chaque broker stocke une ou plusieurs de ces partitions. Plusieurs producteurs et consommateurs peuvent publier et extraire les messages au même moment.</p>
<h3 id="kafka-et-zookeeper">Kafka et Zookeeper<a class="headerlink" href="#kafka-et-zookeeper" title="Permanent link">&para;</a></h3>
<p><a href="https://zookeeper.apache.org/">Zookeeper</a> est un service centralisé permettant de maintenir l'information de configuration, de nommage, de synchronisation et de services de groupe. Ces services sont utilisés par les applications distribuées en général, et par Kafka en particulier. Pour éviter la complexité et difficulté de leur implémentation manuelle, Zookeeper est utilisé.</p>
<p><img alt="Utilisation de Zookeeper avec Kafka" src="../img/tp3/zookeeper-kafka.png" /></p>
<p>Un cluster Kafka consiste typiquement en plusieurs courtiers (Brokers) pour maintenir la répartition de charge. Ces courtiers sont stateless, c'est pour cela qu'ils utilisent Zookeeper pour maintenir l'état du cluster. Un courtier peut gérer des centaines de milliers de lectures et écritures par seconde, et chaque courtier peut gérer des téra-octets de messages sans impact sur la performance.</p>
<p>Zookeeper est utilisé pour gérer et coordonner les courtiers Kafka. Il permet de notifier les producteurs et consommateurs de messages de la présence de tout nouveau courtier, ou de l'échec d'un courtier dans le cluster.</p>
<h3 id="installation">Installation<a class="headerlink" href="#installation" title="Permanent link">&para;</a></h3>
<p>Kafka a été installé sur le même cluster que les deux TP précédents. Suivre les étapes décrites dans la partie <em>Installation</em> du <a href="../tp1/index.html#installation">TP1</a> pour télécharger l'image et exécuter les trois contenaires. Si cela est déjà fait, il suffit de lancer vos machines grâce aux commandes suivantes:</p>
<div class="codehilite"><pre><span></span>  docker start hadoop-master hadoop-slave1 hadoop-slave2
</pre></div>

<p>puis d'entrer dans le contenaire master:</p>
<div class="codehilite"><pre><span></span>    docker <span class="nb">exec</span> -it hadoop-master bash
</pre></div>

<p>Lancer ensuite les démons yarn et hdfs:<br />
<div class="codehilite"><pre><span></span>  ./start-hadoop.sh
</pre></div></p>
<p>Lancer Kafka et Zookeeper en tapant :<br />
<div class="codehilite"><pre><span></span>  ./start-kafka-zookeeper.sh
</pre></div><br />
Les deux démons Kafka et Zookeeper seront lancés. Vous pourrez vérifier cela en tapant <code>jps</code> pour voir quels processus Java sont en exécution, vous devriez trouver les processus suivants:<br />
<div class="codehilite"><pre><span></span>  <span class="m">2756</span> Kafka
  <span class="m">53</span> QuorumPeerMain
  <span class="m">6349</span> Jps
</pre></div></p>
<h2 id="premiere-utilisation-de-kafka">Première utilisation de Kafka<a class="headerlink" href="#premiere-utilisation-de-kafka" title="Permanent link">&para;</a></h2>
<h3 id="creation-dun-topic">Création d'un topic<a class="headerlink" href="#creation-dun-topic" title="Permanent link">&para;</a></h3>
<p>Pour gérer les topics, Kafka fournit une commande appelée <code>kafka-topics.sh</code>.<br />
Dans un nouveau terminal, taper la commande suivante pour créer un nouveau topic appelé "Hello-Kafka".</p>
<div class="codehilite"><pre><span></span>  kafka-topics.sh --create --zookeeper localhost:2181
                  --replication-factor <span class="m">1</span> --partitions <span class="m">1</span>
                  --topic Hello-Kafka
</pre></div>

<div class="admonition warning">
<p class="admonition-title">Attention</p>
<p>Cette commande fonctionne car nous avions rajouté /usr/local/kafka/bin à la variable d'environnement PATH. Si ce n'était pas le cas, on aurait du appeler /usr/local/kafka/bin/kafka-topics.sh</p>
</div>
<p>Pour afficher la liste des topics existants, il faudra utiliser:</p>
<div class="codehilite"><pre><span></span>  kafka-topics.sh --list --zookeeper localhost:2181
</pre></div>

<p>Le résultat devrait être (parmi un grand nombre de lignes d'INFO):</p>
<div class="codehilite"><pre><span></span>  Hello-Kafka
</pre></div>

<h3 id="exemple-producteur-consommateur">Exemple Producteur Consommateur<a class="headerlink" href="#exemple-producteur-consommateur" title="Permanent link">&para;</a></h3>
<p>Kafka fournit un exemple de producteur standard que vous pouvez directement utiliser. Il suffit de taper:</p>
<div class="codehilite"><pre><span></span>  kafka-console-producer.sh --broker-list localhost:9092 --topic Hello-Kafka
</pre></div>

<p>Tout ce que vous taperez dorénavant sur la console sera envoyé à Kafka. L'option <code>--broker-list</code> permet de définir la liste des courtiers auxquels vous enverrez le message. Pour l'instant, vous n'en disposez que d'un, et il est déployé à l'adresse localhost:9092.</p>
<p>Pour lancer un consommateur, utiliser:</p>
<div class="codehilite"><pre><span></span>  kafka-console-consumer.sh --zookeeper localhost:2181 —topic Hello-Kafka
--from-beginning
</pre></div>

<p>Le résultat devra ressembler au suivant:</p>
<p><img alt="Producteur Consommateur Kafka" src="../img/tp3/prod-cons.png" /></p>
<h3 id="configuration-de-plusieurs-brokers">Configuration de plusieurs brokers<a class="headerlink" href="#configuration-de-plusieurs-brokers" title="Permanent link">&para;</a></h3>
<p>Dans ce qui précède, nous avons configuré Kafka pour lancer un seul broker. Pour créer plusieurs brokers, il suffit de dupliquer le fichier <code>$KAFKA_HOME/config/server.properties</code> autant de fois que nécessaire. Dans notre cas, nous allons créer deux autre fichiers: <code>server-one.properties</code> et <code>server-two.properties</code>, puis nous modifions les paramètres suivants comme suit:</p>
<div class="codehilite"><pre><span></span>  <span class="c">### config/server-one.properties</span>
<span class="na">  broker.id</span> <span class="o">=</span> <span class="s">1</span>
<span class="na">  listeners</span><span class="o">=</span><span class="s">PLAINTEXT://localhost:9093</span>
<span class="na">  log.dirs</span><span class="o">=</span><span class="s">/tmp/kafka-logs-1</span>

  <span class="c">### config/server-two.properties</span>
<span class="na">  broker.id</span> <span class="o">=</span> <span class="s">2</span>
<span class="na">  listeners</span><span class="o">=</span><span class="s">PLAINTEXT://localhost:9094</span>
<span class="na">  log.dirs</span><span class="o">=</span><span class="s">/tmp/kafka-logs-2</span>
</pre></div>

<p>Pour démarrer les différents brokers, il suffit d'appeler <code>kafka-server-start.sh</code> avec les nouveaux fichiers de configuration.</p>
<div class="codehilite"><pre><span></span> kafka-server-start.sh <span class="nv">$KAFKA_HOME</span>/config/server.properties <span class="p">&amp;</span>
 kafka-server-start.sh <span class="nv">$KAFKA_HOME</span>/config/server-one.properties <span class="p">&amp;</span>
 kafka-server-start.sh <span class="nv">$KAFKA_HOME</span>/config/server-two.properties <span class="p">&amp;</span>
</pre></div>

<p>Lancer <code>jps</code> pour voir les trois serveurs s'exécuter.</p>
<h2 id="creation-dune-application-personnalisee">Création d'une application personnalisée<a class="headerlink" href="#creation-dune-application-personnalisee" title="Permanent link">&para;</a></h2>
<p>Nous allons dans cette partie créer une application pour publier et consommer des messages de Kafka. Pour cela, nous allons utiliser KafkaProducer API et KafkaConsumer API.</p>
<h3 id="producteur">Producteur<a class="headerlink" href="#producteur" title="Permanent link">&para;</a></h3>
<p>Pour créer un producteur Kafka, créer un fichier dans un répertoire de votre choix dans le contenaire master, intitulé <code>SimpleProducer.java</code>. Son code est le suivant:</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Properties</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.producer.Producer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.producer.KafkaProducer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.producer.ProducerRecord</span><span class="o">;</span>

 <span class="kd">public</span> <span class="kd">class</span> <span class="nc">SimpleProducer</span> <span class="o">{</span>

   <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span><span class="o">{</span>

      <span class="c1">// Verifier que le topic est donne en argument</span>
      <span class="k">if</span><span class="o">(</span><span class="n">args</span><span class="o">.</span><span class="na">length</span> <span class="o">==</span> <span class="mi">0</span><span class="o">){</span>
         <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Entrer le nom du topic&quot;</span><span class="o">);</span>
         <span class="k">return</span><span class="o">;</span>
      <span class="o">}</span>

      <span class="c1">// Assigner topicName a une variable</span>
      <span class="n">String</span> <span class="n">topicName</span> <span class="o">=</span> <span class="n">args</span><span class="o">[</span><span class="mi">0</span><span class="o">].</span><span class="na">toString</span><span class="o">();</span>

      <span class="c1">// Creer une instance de proprietes pour acceder aux configurations du producteur</span>
      <span class="n">Properties</span> <span class="n">props</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Properties</span><span class="o">();</span>

      <span class="c1">// Assigner l&#39;identifiant du serveur kafka</span>
      <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:9092&quot;</span><span class="o">);</span>

      <span class="c1">// Definir un acquittement pour les requetes du producteur</span>
      <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;acks&quot;</span><span class="o">,</span> <span class="s">&quot;all&quot;</span><span class="o">);</span>

      <span class="c1">// Si la requete echoue, le producteur peut reessayer automatiquemt</span>
      <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;retries&quot;</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>

      <span class="c1">// Specifier la taille du buffer size dans la config</span>
      <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;batch.size&quot;</span><span class="o">,</span> <span class="mi">16384</span><span class="o">);</span>

      <span class="c1">// buffer.memory controle le montant total de memoire disponible au producteur pour le buffering</span>
      <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;buffer.memory&quot;</span><span class="o">,</span> <span class="mi">33554432</span><span class="o">);</span>

      <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;key.serializer&quot;</span><span class="o">,</span>
         <span class="s">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="o">);</span>

      <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;value.serializer&quot;</span><span class="o">,</span>
         <span class="s">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="o">);</span>

      <span class="n">Producer</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">producer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">KafkaProducer</span>
         <span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;(</span><span class="n">props</span><span class="o">);</span>

      <span class="k">for</span><span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span>
         <span class="n">producer</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="k">new</span> <span class="n">ProducerRecord</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;(</span><span class="n">topicName</span><span class="o">,</span>
            <span class="n">Integer</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="n">i</span><span class="o">),</span> <span class="n">Integer</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="n">i</span><span class="o">)));</span>
               <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Message envoye avec succes&quot;</span><span class="o">);</span>
               <span class="n">producer</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
   <span class="o">}</span>
 <span class="o">}</span>
</pre></div>

<p>ProducerRecord est une paire clef/valeur envoyée au cluster Kafka. Son constructeur peut prendre 4, 3 ou 2 paramètres, selon le besoin. Les signatures autorisées sont comme suit:</p>
<div class="codehilite"><pre><span></span>  <span class="kd">public</span> <span class="nf">ProducerRecord</span> <span class="o">(</span><span class="n">string</span> <span class="n">topic</span><span class="o">,</span> <span class="kt">int</span> <span class="n">partition</span><span class="o">,</span> <span class="n">k</span> <span class="n">key</span><span class="o">,</span> <span class="n">v</span> <span class="n">value</span><span class="o">){...}</span>
  <span class="kd">public</span> <span class="nf">ProducerRecord</span> <span class="o">(</span><span class="n">string</span> <span class="n">topic</span><span class="o">,</span> <span class="n">k</span> <span class="n">key</span><span class="o">,</span> <span class="n">v</span> <span class="n">value</span><span class="o">){...}</span>
  <span class="kd">public</span> <span class="nf">ProducerRecord</span> <span class="o">(</span><span class="n">string</span> <span class="n">topic</span><span class="o">,</span> <span class="n">v</span> <span class="n">value</span><span class="o">){...}</span>
</pre></div>

<p>Pour compiler ce code, taper dans la console (en vous positionnant dans le répertoire qui contient le fichier SimpleProducer.java):</p>
<div class="codehilite"><pre><span></span>   javac -cp <span class="s2">&quot;</span><span class="nv">$KAFKA_HOME</span><span class="s2">/libs/*&quot;</span>:. SimpleProducer.java
</pre></div>

<p>Lancer ensuite le producer en tapant:</p>
<div class="codehilite"><pre><span></span>   java -cp <span class="s2">&quot;</span><span class="nv">$KAFKA_HOME</span><span class="s2">/libs/*&quot;</span>:. SimpleProducer Hello-Kafka
</pre></div>

<p>Pour voir le résultat saisi dans Kafka, il est possible d'utiliser le consommateur prédéfini de Kafka, à condition d'utiliser le même topic:</p>
<div class="codehilite"><pre><span></span>  kafka-console-consumer.sh --zookeeper localhost:2181 --topic Hello-Kafka --from-beginning
</pre></div>

<p>Le résultat devrait ressembler au suivant:<br />
<div class="codehilite"><pre><span></span>1
2
3
4
5
6
7
8
9
10
</pre></div></p>
<h3 id="consommateur">Consommateur<a class="headerlink" href="#consommateur" title="Permanent link">&para;</a></h3>
<p>Pour créer un consommateur, procéder de même. Créer un fichier SimpleConsumer.java, avec le code suivant:</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Properties</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.KafkaConsumer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.ConsumerRecords</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.clients.consumer.ConsumerRecord</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">SimpleConsumer</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
    <span class="k">if</span><span class="o">(</span><span class="n">args</span><span class="o">.</span><span class="na">length</span> <span class="o">==</span> <span class="mi">0</span><span class="o">){</span>
       <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Entrer le nom du topic&quot;</span><span class="o">);</span>
       <span class="k">return</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="n">String</span> <span class="n">topicName</span> <span class="o">=</span> <span class="n">args</span><span class="o">[</span><span class="mi">0</span><span class="o">].</span><span class="na">toString</span><span class="o">();</span>
    <span class="n">Properties</span> <span class="n">props</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Properties</span><span class="o">();</span>

    <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:9092&quot;</span><span class="o">);</span>
    <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;group.id&quot;</span><span class="o">,</span> <span class="s">&quot;test&quot;</span><span class="o">);</span>
    <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;enable.auto.commit&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">);</span>
    <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;auto.commit.interval.ms&quot;</span><span class="o">,</span> <span class="s">&quot;1000&quot;</span><span class="o">);</span>
    <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;session.timeout.ms&quot;</span><span class="o">,</span> <span class="s">&quot;30000&quot;</span><span class="o">);</span>
    <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;key.deserializer&quot;</span><span class="o">,</span>
       <span class="s">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span><span class="o">);</span>
    <span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;value.deserializer&quot;</span><span class="o">,</span>
       <span class="s">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span><span class="o">);</span>

    <span class="n">KafkaConsumer</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">consumer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">KafkaConsumer</span>
       <span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;(</span><span class="n">props</span><span class="o">);</span>

    <span class="c1">// Kafka Consumer va souscrire a la liste de topics ici</span>
    <span class="n">consumer</span><span class="o">.</span><span class="na">subscribe</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">topicName</span><span class="o">));</span>

    <span class="c1">// Afficher le nom du topic</span>
    <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Souscris au topic &quot;</span> <span class="o">+</span> <span class="n">topicName</span><span class="o">);</span>
    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>

    <span class="k">while</span> <span class="o">(</span><span class="kc">true</span><span class="o">)</span> <span class="o">{</span>
       <span class="n">ConsumerRecords</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">records</span> <span class="o">=</span> <span class="n">consumer</span><span class="o">.</span><span class="na">poll</span><span class="o">(</span><span class="mi">100</span><span class="o">);</span>
       <span class="k">for</span> <span class="o">(</span><span class="n">ConsumerRecord</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">record</span> <span class="o">:</span> <span class="n">records</span><span class="o">)</span>

       <span class="c1">// Afficher l&#39;offset, clef et valeur des enregistrements du consommateur</span>
       <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">printf</span><span class="o">(</span><span class="s">&quot;offset = %d, key = %s, value = %s\n&quot;</span><span class="o">,</span>
          <span class="n">record</span><span class="o">.</span><span class="na">offset</span><span class="o">(),</span> <span class="n">record</span><span class="o">.</span><span class="na">key</span><span class="o">(),</span> <span class="n">record</span><span class="o">.</span><span class="na">value</span><span class="o">());</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>
</pre></div>

<p>Compiler le consommateur avec:<br />
<div class="codehilite"><pre><span></span>  javac -cp <span class="s2">&quot;</span><span class="nv">$KAFKA_HOME</span><span class="s2">/libs/*&quot;</span>:. SimpleConsumer.java
</pre></div></p>
<p>Puis l'exécuter:<br />
<div class="codehilite"><pre><span></span>  java -cp <span class="s2">&quot;</span><span class="nv">$KAFKA_HOME</span><span class="s2">/libs/*&quot;</span>:. SimpleConsumer Hello-Kafka
</pre></div></p>
<p>Le consommateur est maintenant à l'écoute du serveur de messagerie.</p>
<p>Ouvrir un nouveau terminal et relancer le producteur que vous aviez développé tout à l'heure. Le résultat dans le consommateur devrait ressembler à ceci.</p>
<div class="codehilite"><pre><span></span>offset = 32, key = 0, value = 0
offset = 33, key = 1, value = 1
offset = 34, key = 2, value = 2
offset = 35, key = 3, value = 3
offset = 36, key = 4, value = 4
offset = 37, key = 5, value = 5
offset = 38, key = 6, value = 6
offset = 39, key = 7, value = 7
offset = 40, key = 8, value = 8
offset = 41, key = 9, value = 9
</pre></div>

<h2 id="integration-de-kafka-avec-spark">Intégration de Kafka avec Spark<a class="headerlink" href="#integration-de-kafka-avec-spark" title="Permanent link">&para;</a></h2>
<h3 id="utilite">Utilité<a class="headerlink" href="#utilite" title="Permanent link">&para;</a></h3>
<p>Kafka représente une plateforme potentielle pour le messaging et l'intégration de Spark streaming. Kafka agit comme étant le hub central pour les flux de données en temps réel, qui sont ensuite traités avec des algorithmes complexes par Spark Streaming. Une fois les données traitées, Spark Streaming peut publier les résultats dans un autre topic Kafka ou les stokcer dans HDFS, d'autres bases de données ou des dashboards.</p>
<h3 id="realisation">Réalisation<a class="headerlink" href="#realisation" title="Permanent link">&para;</a></h3>
<p>Pour faire cela, nous allons réaliser un exemple simple, où Spark Streaming consomme des données de Kafka pour réaliser l'éternel wordcount.</p>
<p>Dans votre machine locale, ouvrir IntelliJ IDEA (ou tout autre IDE de votre choix) et créer un nouveau projet Maven, avec les propriétés suivantes:</p>
<div class="codehilite"><pre><span></span><span class="na">  groupId</span><span class="o">:</span> <span class="s">spark.kafka</span>
<span class="na">  artifactId</span><span class="o">:</span> <span class="s">stream-kafka-spark</span>
<span class="na">  version</span><span class="o">:</span> <span class="s">1</span>
</pre></div>

<p>Une fois le projet créé, modifier le fichier pom.xml pour qu'il ressemble à ce qui suit:</p>
<p><div class="codehilite"><pre><span></span><span class="cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
<span class="nt">&lt;project</span> <span class="na">xmlns=</span><span class="s">&quot;http://maven.apache.org/POM/4.0.0&quot;</span>
         <span class="na">xmlns:xsi=</span><span class="s">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span>
         <span class="na">xsi:schemaLocation=</span><span class="s">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span><span class="nt">&gt;</span>
    <span class="nt">&lt;modelVersion&gt;</span>4.0.0<span class="nt">&lt;/modelVersion&gt;</span>

    <span class="nt">&lt;groupId&gt;</span>spark.kafka<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>stream-kafka-spark<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>1<span class="nt">&lt;/version&gt;</span>

    <span class="nt">&lt;dependencies&gt;</span>
        <span class="nt">&lt;dependency&gt;</span>
            <span class="nt">&lt;groupId&gt;</span>org.apache.spark<span class="nt">&lt;/groupId&gt;</span>
            <span class="nt">&lt;artifactId&gt;</span>spark-core_2.11<span class="nt">&lt;/artifactId&gt;</span>
            <span class="nt">&lt;version&gt;</span>2.2.1<span class="nt">&lt;/version&gt;</span>
        <span class="nt">&lt;/dependency&gt;</span>
        <span class="nt">&lt;dependency&gt;</span>
            <span class="nt">&lt;groupId&gt;</span>org.apache.spark<span class="nt">&lt;/groupId&gt;</span>
            <span class="nt">&lt;artifactId&gt;</span>spark-streaming_2.11<span class="nt">&lt;/artifactId&gt;</span>
            <span class="nt">&lt;version&gt;</span>2.2.1<span class="nt">&lt;/version&gt;</span>
        <span class="nt">&lt;/dependency&gt;</span>
        <span class="nt">&lt;dependency&gt;</span>
            <span class="nt">&lt;groupId&gt;</span>org.apache.spark<span class="nt">&lt;/groupId&gt;</span>
            <span class="nt">&lt;artifactId&gt;</span>spark-streaming-kafka-0-8_2.11<span class="nt">&lt;/artifactId&gt;</span>
            <span class="nt">&lt;version&gt;</span>2.2.0<span class="nt">&lt;/version&gt;</span>
        <span class="nt">&lt;/dependency&gt;</span>
        <span class="nt">&lt;dependency&gt;</span>
            <span class="nt">&lt;groupId&gt;</span>org.apache.kafka<span class="nt">&lt;/groupId&gt;</span>
            <span class="nt">&lt;artifactId&gt;</span>kafka-clients<span class="nt">&lt;/artifactId&gt;</span>
            <span class="nt">&lt;version&gt;</span>0.8.2.0<span class="nt">&lt;/version&gt;</span>
        <span class="nt">&lt;/dependency&gt;</span>
    <span class="nt">&lt;/dependencies&gt;</span>

    <span class="nt">&lt;build&gt;</span>
        <span class="nt">&lt;sourceDirectory&gt;</span>src/main/java<span class="nt">&lt;/sourceDirectory&gt;</span>
        <span class="nt">&lt;testSourceDirectory&gt;</span>src/test/java<span class="nt">&lt;/testSourceDirectory&gt;</span>
        <span class="nt">&lt;plugins&gt;</span>
            <span class="nt">&lt;plugin&gt;</span>
                <span class="nt">&lt;groupId&gt;</span>org.apache.maven.plugins<span class="nt">&lt;/groupId&gt;</span>
                <span class="nt">&lt;artifactId&gt;</span>maven-compiler-plugin<span class="nt">&lt;/artifactId&gt;</span>
                <span class="nt">&lt;configuration&gt;</span>
                    <span class="nt">&lt;source&gt;</span>1.8<span class="nt">&lt;/source&gt;</span>
                    <span class="nt">&lt;target&gt;</span>1.8<span class="nt">&lt;/target&gt;</span>
                <span class="nt">&lt;/configuration&gt;</span>
            <span class="nt">&lt;/plugin&gt;</span>
            <span class="c">&lt;!--</span>
<span class="c">                         Bind the maven-assembly-plugin to the package phase</span>
<span class="c">              this will create a jar file without the storm dependencies</span>
<span class="c">              suitable for deployment to a cluster.</span>
<span class="c">             --&gt;</span>
            <span class="nt">&lt;plugin&gt;</span>
                <span class="nt">&lt;artifactId&gt;</span>maven-assembly-plugin<span class="nt">&lt;/artifactId&gt;</span>
                <span class="nt">&lt;configuration&gt;</span>
                    <span class="nt">&lt;archive&gt;</span>
                        <span class="nt">&lt;manifest&gt;</span>
                            <span class="nt">&lt;mainClass&gt;</span>tn.insat.tp3.SparkKafkaWordCount<span class="nt">&lt;/mainClass&gt;</span>
                        <span class="nt">&lt;/manifest&gt;</span>
                    <span class="nt">&lt;/archive&gt;</span>
                    <span class="nt">&lt;descriptorRefs&gt;</span>
                        <span class="nt">&lt;descriptorRef&gt;</span>jar-with-dependencies<span class="nt">&lt;/descriptorRef&gt;</span>
                    <span class="nt">&lt;/descriptorRefs&gt;</span>
                <span class="nt">&lt;/configuration&gt;</span>
            <span class="nt">&lt;/plugin&gt;</span>
        <span class="nt">&lt;/plugins&gt;</span>
    <span class="nt">&lt;/build&gt;</span>

<span class="nt">&lt;/project&gt;</span>
</pre></div><br />
Le plugin <em>maven-assembly-plugin</em> est utile pour pouvoir créer un jar contenant toutes les dépendances du projet.</p>
<p>Créer ensuite un package <em>tn.insat.tp3</em> et une classe <em>SparkKafkaWordCount</em>. Le code de cette classe sera comme suit:</p>
<div class="codehilite"><pre><span></span><span class="kn">package</span> <span class="nn">tn.insat.tp3</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.SparkConf</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.Duration</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.api.java.*</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.kafka.KafkaUtils</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">scala.Tuple2</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.HashMap</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Map</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.regex.Pattern</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">SparkKafkaWordCount</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="n">Pattern</span> <span class="n">SPACE</span> <span class="o">=</span> <span class="n">Pattern</span><span class="o">.</span><span class="na">compile</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">);</span>

    <span class="kd">private</span> <span class="nf">SparkKafkaWordCount</span><span class="o">()</span> <span class="o">{</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">args</span><span class="o">.</span><span class="na">length</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">System</span><span class="o">.</span><span class="na">err</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Usage: SparkKafkaWordCount &lt;zkQuorum&gt; &lt;group&gt; &lt;topics&gt; &lt;numThreads&gt;&quot;</span><span class="o">);</span>
            <span class="n">System</span><span class="o">.</span><span class="na">exit</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
        <span class="o">}</span>

        <span class="n">SparkConf</span> <span class="n">sparkConf</span> <span class="o">=</span> <span class="k">new</span> <span class="n">SparkConf</span><span class="o">().</span><span class="na">setAppName</span><span class="o">(</span><span class="s">&quot;SparkKafkaWordCount&quot;</span><span class="o">);</span>
        <span class="c1">// Creer le contexte avec une taille de batch de 2 secondes</span>
        <span class="n">JavaStreamingContext</span> <span class="n">jssc</span> <span class="o">=</span> <span class="k">new</span> <span class="n">JavaStreamingContext</span><span class="o">(</span><span class="n">sparkConf</span><span class="o">,</span>
            <span class="k">new</span> <span class="n">Duration</span><span class="o">(</span><span class="mi">2000</span><span class="o">));</span>

        <span class="kt">int</span> <span class="n">numThreads</span> <span class="o">=</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">args</span><span class="o">[</span><span class="mi">3</span><span class="o">]);</span>
        <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="n">topicMap</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;&gt;();</span>
        <span class="n">String</span><span class="o">[]</span> <span class="n">topics</span> <span class="o">=</span> <span class="n">args</span><span class="o">[</span><span class="mi">2</span><span class="o">].</span><span class="na">split</span><span class="o">(</span><span class="s">&quot;,&quot;</span><span class="o">);</span>
        <span class="k">for</span> <span class="o">(</span><span class="n">String</span> <span class="n">topic</span><span class="o">:</span> <span class="n">topics</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">topicMap</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">topic</span><span class="o">,</span> <span class="n">numThreads</span><span class="o">);</span>
        <span class="o">}</span>

        <span class="n">JavaPairReceiverInputDStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">messages</span> <span class="o">=</span>
                <span class="n">KafkaUtils</span><span class="o">.</span><span class="na">createStream</span><span class="o">(</span><span class="n">jssc</span><span class="o">,</span> <span class="n">args</span><span class="o">[</span><span class="mi">0</span><span class="o">],</span> <span class="n">args</span><span class="o">[</span><span class="mi">1</span><span class="o">],</span> <span class="n">topicMap</span><span class="o">);</span>

        <span class="n">JavaDStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">lines</span> <span class="o">=</span> <span class="n">messages</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">Tuple2</span><span class="o">::</span><span class="n">_2</span><span class="o">);</span>

        <span class="n">JavaDStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">words</span> <span class="o">=</span>
                <span class="n">lines</span><span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">SPACE</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="n">x</span><span class="o">)).</span><span class="na">iterator</span><span class="o">());</span>

        <span class="n">JavaPairDStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span>
                <span class="n">words</span><span class="o">.</span><span class="na">mapToPair</span><span class="o">(</span><span class="n">s</span> <span class="o">-&gt;</span> <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="n">s</span><span class="o">,</span> <span class="mi">1</span><span class="o">))</span>
                     <span class="o">.</span><span class="na">reduceByKey</span><span class="o">((</span><span class="n">i1</span><span class="o">,</span> <span class="n">i2</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">i1</span> <span class="o">+</span> <span class="n">i2</span><span class="o">);</span>

        <span class="n">wordCounts</span><span class="o">.</span><span class="na">print</span><span class="o">();</span>
        <span class="n">jssc</span><span class="o">.</span><span class="na">start</span><span class="o">();</span>
        <span class="n">jssc</span><span class="o">.</span><span class="na">awaitTermination</span><span class="o">();</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>

<p>KafkaUtils API est utilisée pour connecter le cluster Kafka à Spark Streaming. La méthode <em>createStream</em> est utilisée, pour créer un flux en entrée, qui extrait les messages des courtiers Kafka. Elle prend en paramètres:</p>
<ul>
<li>L' objet StreamingContext</li>
<li>Le(s) serveur(s) Zookeeper</li>
<li>L'identifiant du groupe du consommateur courant</li>
<li>Une Map des topics à consommateur</li>
</ul>
<p>Créer une configuration Maven pour lancer la commande:</p>
<div class="codehilite"><pre><span></span>  mvn clean compile assembly:single
</pre></div>

<p>Dans le répertoire target, un fichier stream-kafka-spark-1-jar-with-dependencies.jar est créé. Copier ce fichier dans le contenaire master, en utilisant le terminal d'IntelliJ:</p>
<div class="codehilite"><pre><span></span>  docker cp target/stream-kafka-spark-1-jar-with-dependencies.jar hadoop-master:/root
</pre></div>

<p>Revenir à votre contenaire master, et lancer la commande spark-submit pour lancer l'écouteur de streaming spark.</p>
<div class="codehilite"><pre><span></span>spark-submit --class tn.insat.tp3.SparkKafkaWordCount
             --master local<span class="o">[</span><span class="m">2</span><span class="o">]</span>
             stream-kafka-spark-1-jar-with-dependencies.jar
             localhost:2181 <span class="nb">test</span> Hello-Kafka <span class="m">1</span> &gt;&gt; out
</pre></div>

<p>Les quatre options à la fin de la commande sont requises par la classe  SparkKafkaWordCount et représentent respectivement l'adresse de zookeeper, le nom du groupe auquel appartient le consommateur, le nom du topic et le nombre de threads utilisés.</p>
<div class="admonition tip">
<p class="admonition-title">Remarque</p>
<p>>&gt;out est utilisée pour stocker les résultats produits par spark streaming dans un fichier appelé out.</p>
</div>
<p>Dans un autre terminal, lancer le producteur prédéfini de Kafka pour tester la réaction du consommateur spark streaming:</p>
<div class="codehilite"><pre><span></span>kafka-console-producer.sh --broker-list localhost:9092 --topic Hello-Kafka
</pre></div>

<p>Ecrire du texte dans la fenêtre du producteur. Ensuite, arrêter le flux de spark-submit, et observer le contenu du fichier out. Il devra ressembler à ce qui suit:</p>
<p><img alt="Kafka et Spark" src="../img/tp3/prod-cons-kafka-spark.png" /></p>
<h2 id="homework">Homework<a class="headerlink" href="#homework" title="Permanent link">&para;</a></h2>
<p>Pour votre projet, vous allez utiliser Kafka pour gérer les flux entrants et les envoyer à Spark. Ces mêmes données (ou une partie de ces données) seront également stockés dans HDFS pour un traitement par lot ultérieur.<br />
Réaliser les liaisons nécessaires entre Kafka et Spark, puis Kafka et HDFS. Vous devez avoir une idée sur les traitements par lot que vous allez réaliser, pour savoir quelles données seront stockées dans HDFS.</p>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../tp2/" title="TP2 - Apache Spark" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                TP2 - Apache Spark
              </span>
            </div>
          </a>
        
        
          <a href="../tp4/" title="TP4 - HBase" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                TP4 - HBase
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2017 - 2018 Lilia Sfaxi
          </div>
        
        powered by
        <a href="http://www.mkdocs.org" title="MkDocs">MkDocs</a>
        and
        <a href="http://squidfunk.github.io/mkdocs-material/" title="Material for MkDocs">
          Material for MkDocs</a>
      </div>
      
        
  <div class="md-footer-social">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    
      <a href="http://liliasfaxi.wix.com/liliasfaxi" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://github.com/liliasfaxi" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com/lillitou" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://www.linkedin.com/in/liliasfaxi/" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/raphael-min.js"></script>
      <script src="../assets/javascripts/flowchart.js"></script>
      <script src="../assets/javascripts/application-e3caa82af6.js"></script>
      
      
      <script>app.initialize({url:{base:".."}})</script>
      
        <script src="../search/require.js"></script>
      
        <script src="../search/search.js"></script>
      
    
    
      
      <script>!function(e,t,a,n,o,c,i){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,c=t.createElement(a),i=t.getElementsByTagName(a)[0],c.async=1,c.src=n,i.parentNode.insertBefore(c,i)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","None","auto"),ga("set","anonymizeIp",!0),ga("send","pageview");var links=document.getElementsByTagName("a");Array.prototype.map.call(links,function(e){e.host!=document.location.host&&e.addEventListener("click",function(){var t=e.getAttribute("data-md-action")||"follow";ga("send","event","outbound",t,e.href)})});var query=document.forms.search.query;query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})</script>
      
    
  </body>
</html>